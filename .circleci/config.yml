version: 2.1
orbs:
  slack: circleci/slack@3.4.2
jobs:
  build:
    docker:
      - image: circleci/python:3.8
    steps:
      - checkout
      - restore_cache:
          keys:
            - pip_cache-{{ checksum "requirements.txt" }}
            - pip_cache
      - run:
          name: Install mandatory dependencies
          command: pip install -r requirements.txt
      - run:
          name: Run tests without optional dependencies
          command: |
            mkdir test-results
            # In a stable build results will be overwritten by the run with optional dependencies,
            # but if one of these tests fails, we still want them.
            pytest --junitxml=test-results/junit.xml
      - run:
          name: Install optional dependencies
          command: |
            pip install bsddb3 plyvel
      - save_cache:
          paths:
            - ~/.cache/pip
          key: pip_cache-{{ checksum "requirements.txt"}}
      - run:
          name: Run tests with optional dependencies
          command: |
            pytest --junitxml=test-results/junit.xml
      - store_test_results:
          path: test-results
      - restore_cache:
          keys:
            - etl-data-{{ checksum "mowgli_etl/pipeline/rpi_combined/rpi_combined_pipeline.py" }}
      - run:
          name: Generate RPI combined CSKG CSV (master branch only)
          command: |
            if [ "${CIRCLE_BRANCH}" == "master" ]; then
              mkdir -p cskg
              python -m mowgli_etl.cli etl rpi_combined --data-dir-path cskg
            fi
      #      - run:
      #          name: Generate RPI combined CSKG RDF (master branch only)
      #          command: |
      #            if [ "${CIRCLE_BRANCH}" == "master" ]; then
      #              python3 -m mowgli_etl.cli etl rdf --data-dir-path cskg --nodes-csv-file-path cskg/rpi_combined/loaded/nodes.csv --edges-csv-file-path cskg/rpi_combined/loaded/edges.csv --pipeline-id rpi-combined-rdf
      #            fi
      - save_cache:
          key: etl-data-{{ checksum "mowgli_etl/pipeline/rpi_combined/rpi_combined_pipeline.py" }}
          paths:
            - cskg/extracted
      - run:
          name: Archive artifacts (master branch only)
          command: |
            if [ "${CIRCLE_BRANCH}" == "master" ]; then
              cd cskg
              for dir in `ls`; do
                mv "$dir/loaded/"*.csv "$dir/" || true
                mv "$dir/loaded/"*.trig "$dir/" || true
                mv "$dir/loaded/"*.ttl "$dir/" || true
                rm -fr "$dir/extracted" "$dir/transformed" "$dir/loaded"
              done
              cd ..
              tar -cvjSf cskg.tar.bz2 cskg
            else
              touch cskg.tar.bz2
            fi
#      - run:
#          name: Upload CSKG to Drive (master branch only)
#          command: |
#            if [ "${CIRCLE_BRANCH}" == "master" ]; then
#              service_file_path="service_file_key.json"
#              echo "$GCLOUD_SERVICE_KEY" > "$service_file_path"
#              python3 -m mowgli_etl.cli drive-upload --file-path=cskg.tar.bz2  --file-id="$CSKG_FILE_ID" --service-account-file="$service_file_path"
#            fi
      - store_artifacts:
          path: cskg.tar.bz2
      - slack/status
