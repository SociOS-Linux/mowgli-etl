version: 2
jobs:
  etl-py:
    docker:
      - image: circleci/python:3.8
    steps:
      - checkout
      - restore_cache:
          keys:
            - pip_cache-{{ checksum "etl/requirements.txt" }}
            - pip_cache
      - run:
          name: Install mandatory dependencies
          command: pip install -r etl/requirements.txt
      - run:
          name: Run tests without optional dependencies
          command: |
            cd etl
            mkdir test-results
            # In a stable build results will be overwritten by the run with optional dependencies,
            # but if one of these tests fails, we still want them.
            pytest --junitxml=test-results/junit.xml
      - run:
          name: Install optional dependencies
          command: |
            pip install bsddb3 plyvel
      - save_cache:
          paths:
            - ~/.cache/pip
          key: pip_cache-{{ checksum "etl/requirements.txt"}}
      - run:
          name: Run tests with optional dependencies
          command: |
            cd etl
            pytest --junitxml=test-results/junit.xml
      - store_test_results:
          path: test-results
      - run:
          name: Generate RPI combined CSKG CSV (master branch only)
          command: |
            if [ "${CIRCLE_BRANCH}" == "master" ]; then
              cd etl
              mkdir cskg
              python -m mowgli_etl.cli etl rpi_combined --data-dir-path cskg
            fi
      #      - run:
      #          name: Generate RPI combined CSKG RDF (master branch only)
      #          command: |
      #            if [ "${CIRCLE_BRANCH}" == "master" ]; then
      #              python3 -m mowgli_etl.cli etl rdf --data-dir-path cskg --nodes-csv-file-path cskg/rpi_combined/loaded/nodes.csv --edges-csv-file-path cskg/rpi_combined/loaded/edges.csv --pipeline-id rpi-combined-rdf
      #            fi
      - run:
          name: Archive artifacts (master branch only)
          command: |
            if [ "${CIRCLE_BRANCH}" == "master" ]; then
              cd etl/cskg
              for dir in `ls`; do
                mv "$dir/loaded/"*.csv "$dir/" || true
                mv "$dir/loaded/"*.trig "$dir/" || true
                mv "$dir/loaded/"*.ttl "$dir/" || true
                rm -fr "$dir/extracted" "$dir/transformed" "$dir/loaded"
              done
              cd ..
              tar -cvjSf cskg.tar.bz2 cskg
            else
              touch cskg.tar.bz2
            fi
      - run:
          name: Upload CSKG to Drive (master branch only)
          command: |
            if [ "${CIRCLE_BRANCH}" == "master" ]; then
              cd etl
              service_file_path="service_file_key.json"
              cat <<< "$GCLOUD_SERVICE_KEY" > "$service_file_path"
              python3 -m mowgli_etl.cli drive-upload --file-path=cskg.tar.bz2  --file-id="$CSKG_FILE_ID" --service-account-file="$service_file_path"
            fi
      - store_artifacts:
          path: cskg.tar.bz2
  gui-docker:
    docker:
      - image: circleci/python:3.8
    steps:
      - checkout
      - setup_remote_docker
      - run:
          name: Build
          command: |
            cd gui
            docker-compose build
      - run:
          name: Run
          background: true
          command: |
            cd gui
            docker-compose up --abort-on-container-exit
      - run:
          name: Wait for the server to start
          command: |
            sleep 60
      - run:
          name: Bootstrap the database
          command: |
            cd gui
            script/bootstrap-neo4j
      - run:
          name: Load the database
          command: |
            cd gui
            # Can't do volume mounts in CircleCI Docker, so have to copy
            docker cp conf/test_data/edges.csv neo4j:/var/lib/neo4j/import/edges.csv
            docker cp conf/test_data/nodes.csv neo4j:/var/lib/neo4j/import/nodes.csv
            script/load-neo4j
  gui-scala:
    docker:
      - image: circleci/openjdk:11
      - image: neo4j:4.0.4
        name: neo4j
        environment:
          NEO4J_AUTH: neo4j/nC1aB4mji623s2Zs
          NEO4JLABS_PLUGINS: "[\"apoc\"]"
    steps:
      - checkout
      - restore_cache:
          key: sbt-cache-v1
# Can't call docker-exec on secondary images.
#      - run:
#          name: Bootstrap neo4j
#          command: |
#            gui/script/bootstrap-neo4j
      - run:
          name: Build and test
          command: |
            sbt test
      - store_test_results:
          path: gui/target/test-reports
      - save_cache:
          key: sbt-cache-v1
          paths:
            - "~/.ivy2/cache"
            - "~/.m2"
            - "~/.sbt"
workflows:
  version: 2
  etl:
    jobs:
      - etl-py
  gui:
    jobs:
      - gui-docker
      - gui-scala
